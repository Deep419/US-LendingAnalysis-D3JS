{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lending Tree APR Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from subprocess import call\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Activation, Dropout, ReLU\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.models import Model\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 595 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "offer_status = pd.read_csv('data/RULO_OfferStatusChange.csv', low_memory=False)\n",
    "questioner = pd.read_csv('data/RULO_Questioner_Data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "months= ['JAN','FEB','MAR','APR','MAY','JUNE', 'JULY', 'AUGUST','SEP']\n",
    "data=None\n",
    "i = 0;\n",
    "for month in months:\n",
    "    filename = \"./data/Offer_2018-\" + months[i] + \".csv\"\n",
    "    sheet_data = pd.read_csv(filename)\n",
    "    if data is None:\n",
    "        data = sheet_data\n",
    "    else:\n",
    "        data = pd.concat([data, sheet_data], axis=0)\n",
    "    i+=1\n",
    "data['AmortizationType']=data['AmortizationType'].apply(lambda x: 'Fixed' if x=='FIXED' else x)\n",
    "data.drop('Status', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge all the three dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_status_prod=pd.merge(data, offer_status,on=['QuestionerId','QuotesId','OfferId'], how='inner', suffixes=['_offer','_offerProd'])\n",
    "offer_data_questioner=pd.merge(offer_status_prod, questioner,on=['QuestionerId','QuotesId'], how='inner', suffixes=['_offer','_questioner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Selection**\n",
    "\n",
    "We did select features based on obvious significance and availability and try including and excluding other features to see it that improves the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_columns = ['EstimatedCreditScore','EstimatedPropertyValue','CurrentMortgageBalance','LoanAmountRequested',\n",
    "                   'RequestedLoanTypeId','PropertyState', 'Veteran', 'PropertyTypeId', 'PropertyUse', 'IsFHALoan', \n",
    "                   'IsJumboLoan', 'IsVALoan','APRPercentage']\n",
    "\n",
    "data=offer_data_questioner[desired_columns].dropna().reset_index(drop=True)\n",
    "\n",
    "features_cols = desired_columns[:-1]\n",
    "target_col = desired_columns[-1]\n",
    "numeric_cols = desired_columns[0:4]\n",
    "#Update the propertyType amd LoanType to category which will make it easy for dummy encoding\n",
    "data.PropertyTypeId = data.PropertyTypeId.apply(lambda x: \"Type_\"+str(x))\n",
    "data.RequestedLoanTypeId = data.RequestedLoanTypeId.apply(lambda x: \"Type_\"+str(x))\n",
    "#Seperate Feature and target and perform dummy encoding the categorical column\n",
    "features = pd.get_dummies(data[features_cols])\n",
    "target = data[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Normalization on of the numeric columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_cols:\n",
    "    features[col]=(features[col]-features[col].mean())/features[col].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Conversion:**\n",
    "We will convert pandas dataframe to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(features)\n",
    "y = np.array(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 0.222\n",
      "Validation MSE: 0.213\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression().fit(train_X, train_y)\n",
    "train_pred = lr.predict(train_X)\n",
    "train_mse = mean_squared_error(train_pred, train_y)\n",
    "print(\"Training MSE: %.3f\" %train_mse)\n",
    "\n",
    "val_pred = lr.predict(val_X)\n",
    "val_mse = mean_squared_error(val_pred, val_y)\n",
    "print(\"Validation MSE: %.3f\" %val_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x243b1ecfd68>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed=11\n",
    "feature_size = train_X.shape[1]\n",
    "input_layer = Input(shape=(feature_size,))\n",
    "last_layer = Dense(300, input_dim=feature_size,kernel_initializer=\n",
    "                                keras.initializers.glorot_normal(seed=seed))(input_layer)\n",
    "last_layer = Dropout(0.5)(last_layer)\n",
    "last_layer = PReLU(weights=None)(last_layer)\n",
    "\n",
    "last_layer= Dense(100, kernel_initializer=keras.initializers.glorot_normal(seed=seed))(last_layer)\n",
    "last_layer = Dropout(0.5)(last_layer)\n",
    "last_layer = PReLU(weights=None, alpha_initializer=\"zero\")(last_layer)\n",
    "\n",
    "last_layer = Dense(50,  kernel_initializer=keras.initializers.glorot_normal(seed=seed))(last_layer)\n",
    "last_layer = Dropout(0.5)(last_layer)\n",
    "last_layer = PReLU(weights=None, alpha_initializer=\"zero\")(last_layer)\n",
    "\n",
    "last_layer = Dense(10, kernel_initializer=keras.initializers.glorot_normal(seed=seed))(last_layer)\n",
    "last_layer = Dropout(0.3)(last_layer)\n",
    "last_layer = PReLU(weights=None, alpha_initializer=\"zero\")(last_layer)                                             \n",
    "\n",
    "output_layer = Dense(1,kernel_initializer=keras.initializers.glorot_normal(seed=seed))(last_layer)\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=Adam(0.001))\n",
    "model.fit(train_X, train_y, validation_data=(val_X, val_y), epochs=1500, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction on Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 0.080\n",
      "Validation MSE: 0.159\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.predict(train_X)\n",
    "train_mse = mean_squared_error(train_pred, train_y)\n",
    "print(\"Training MSE: %.3f\" %train_mse)\n",
    "\n",
    "val_pred = model.predict(val_X)\n",
    "val_mse = mean_squared_error(val_pred, val_y)\n",
    "print(\"Validation MSE: %.3f\" %val_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this model is overfitting a bit though it is performing better then the linear regression and the overfitting can be reduced more by tuning the dropouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LBFGS**:\n",
    "\n",
    "Let's try teh lbfgs optimizer which which uses 2nd order derivative of the lost function and see if that improves out learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 0.062\n",
      "Validation MSE: 0.061\n"
     ]
    }
   ],
   "source": [
    "mlr = MLPRegressor(hidden_layer_sizes=(100,10), activation='relu', solver='lbfgs', alpha=0.001, batch_size=64, \n",
    "                   learning_rate='constant', learning_rate_init=0.001, max_iter=3000, \n",
    "                   random_state=11, tol=0.0001, verbose=False, warm_start=False, \n",
    "                   early_stopping=True, epsilon=1e-08)\n",
    "\n",
    "mlr.fit(X, y)\n",
    "train_pred = mlr.predict(train_X)\n",
    "train_mse = mean_squared_error(train_pred, train_y)\n",
    "print(\"Training MSE: %.3f\" %train_mse)\n",
    "\n",
    "val_pred = mlr.predict(val_X)\n",
    "val_mse = mean_squared_error(val_pred, val_y)\n",
    "print(\"Validation MSE: %.3f\" %val_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this approach gave us a better MSE with neural network then the one we used previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**See Some prediction of the APR on the validation data**\n",
    "\n",
    "First columns shows the the predicted APR and the second column shows actual APR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted APR</th>\n",
       "      <th>Actual APR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.848653</td>\n",
       "      <td>3.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.871358</td>\n",
       "      <td>4.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.334078</td>\n",
       "      <td>4.567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.430230</td>\n",
       "      <td>3.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.376498</td>\n",
       "      <td>4.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.585208</td>\n",
       "      <td>4.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.991868</td>\n",
       "      <td>3.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.174042</td>\n",
       "      <td>4.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.656466</td>\n",
       "      <td>3.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.713638</td>\n",
       "      <td>3.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.771778</td>\n",
       "      <td>5.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.881111</td>\n",
       "      <td>3.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.145664</td>\n",
       "      <td>3.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.122804</td>\n",
       "      <td>3.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.371995</td>\n",
       "      <td>5.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.583981</td>\n",
       "      <td>4.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.238817</td>\n",
       "      <td>4.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.565704</td>\n",
       "      <td>4.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.782765</td>\n",
       "      <td>3.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.337076</td>\n",
       "      <td>5.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.340655</td>\n",
       "      <td>4.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.500628</td>\n",
       "      <td>4.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.979564</td>\n",
       "      <td>5.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.442630</td>\n",
       "      <td>4.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.613940</td>\n",
       "      <td>4.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.706472</td>\n",
       "      <td>3.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.165610</td>\n",
       "      <td>4.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.310852</td>\n",
       "      <td>4.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.399934</td>\n",
       "      <td>4.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.913600</td>\n",
       "      <td>4.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>4.901539</td>\n",
       "      <td>4.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>5.138587</td>\n",
       "      <td>5.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>4.217987</td>\n",
       "      <td>4.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>4.627829</td>\n",
       "      <td>4.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>4.960790</td>\n",
       "      <td>4.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>5.079309</td>\n",
       "      <td>4.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>3.777004</td>\n",
       "      <td>3.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>4.021754</td>\n",
       "      <td>4.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>4.094655</td>\n",
       "      <td>4.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>4.065051</td>\n",
       "      <td>3.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>4.715432</td>\n",
       "      <td>4.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>4.023165</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>4.734848</td>\n",
       "      <td>4.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>4.686838</td>\n",
       "      <td>4.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>4.033504</td>\n",
       "      <td>3.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>4.147105</td>\n",
       "      <td>4.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>5.038238</td>\n",
       "      <td>4.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>5.381683</td>\n",
       "      <td>5.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>3.921093</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>3.555098</td>\n",
       "      <td>3.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>5.329214</td>\n",
       "      <td>5.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>4.328213</td>\n",
       "      <td>4.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>3.788641</td>\n",
       "      <td>4.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>4.609090</td>\n",
       "      <td>4.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>4.120794</td>\n",
       "      <td>3.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>4.756974</td>\n",
       "      <td>4.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>4.646229</td>\n",
       "      <td>4.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>5.617016</td>\n",
       "      <td>5.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>3.560101</td>\n",
       "      <td>3.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>4.365460</td>\n",
       "      <td>4.177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1192 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predicted APR  Actual APR\n",
       "0          3.848653       3.711\n",
       "1          4.871358       4.787\n",
       "2          4.334078       4.567\n",
       "3          3.430230       3.433\n",
       "4          4.376498       4.360\n",
       "5          4.585208       4.627\n",
       "6          3.991868       3.995\n",
       "7          4.174042       4.106\n",
       "8          3.656466       3.574\n",
       "9          3.713638       3.764\n",
       "10         4.771778       5.187\n",
       "11         3.881111       3.962\n",
       "12         4.145664       3.831\n",
       "13         3.122804       3.368\n",
       "14         5.371995       5.035\n",
       "15         4.583981       4.658\n",
       "16         4.238817       4.167\n",
       "17         4.565704       4.588\n",
       "18         3.782765       3.825\n",
       "19         5.337076       5.663\n",
       "20         4.340655       4.547\n",
       "21         5.500628       4.745\n",
       "22         4.979564       5.025\n",
       "23         4.442630       4.447\n",
       "24         4.613940       4.616\n",
       "25         3.706472       3.738\n",
       "26         5.165610       4.745\n",
       "27         4.310852       4.344\n",
       "28         4.399934       4.427\n",
       "29         3.913600       4.166\n",
       "...             ...         ...\n",
       "1162       4.901539       4.994\n",
       "1163       5.138587       5.153\n",
       "1164       4.217987       4.329\n",
       "1165       4.627829       4.646\n",
       "1166       4.960790       4.589\n",
       "1167       5.079309       4.855\n",
       "1168       3.777004       3.656\n",
       "1169       4.021754       4.317\n",
       "1170       4.094655       4.414\n",
       "1171       4.065051       3.973\n",
       "1172       4.715432       4.971\n",
       "1173       4.023165       4.000\n",
       "1174       4.734848       4.269\n",
       "1175       4.686838       4.669\n",
       "1176       4.033504       3.875\n",
       "1177       4.147105       4.462\n",
       "1178       5.038238       4.962\n",
       "1179       5.381683       5.545\n",
       "1180       3.921093       4.000\n",
       "1181       3.555098       3.313\n",
       "1182       5.329214       5.238\n",
       "1183       4.328213       4.059\n",
       "1184       3.788641       4.618\n",
       "1185       4.609090       4.502\n",
       "1186       4.120794       3.985\n",
       "1187       4.756974       4.811\n",
       "1188       4.646229       4.452\n",
       "1189       5.617016       5.336\n",
       "1190       3.560101       3.817\n",
       "1191       4.365460       4.177\n",
       "\n",
       "[1192 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Predicted APR\":val_pred, \"Actual APR\":val_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-cpu",
   "language": "python",
   "name": "tensorflow-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
